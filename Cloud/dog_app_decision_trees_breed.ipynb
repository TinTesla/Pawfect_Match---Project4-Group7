{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed App: Predicting Group type based on featureset\n",
    "# Method : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing AKC (American Kanine Corp) Dataset Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>description</th>\n",
       "      <th>temperament</th>\n",
       "      <th>popularity</th>\n",
       "      <th>min_height</th>\n",
       "      <th>max_height</th>\n",
       "      <th>min_weight</th>\n",
       "      <th>max_weight</th>\n",
       "      <th>min_expectancy</th>\n",
       "      <th>max_expectancy</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_level_value</th>\n",
       "      <th>energy_level_category</th>\n",
       "      <th>trainability_value</th>\n",
       "      <th>trainability_category</th>\n",
       "      <th>demeanor_value</th>\n",
       "      <th>demeanor_category</th>\n",
       "      <th>akc_breed</th>\n",
       "      <th>kaggle_breed</th>\n",
       "      <th>Img_Link</th>\n",
       "      <th>group_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>The Affen’s apish look has been described many...</td>\n",
       "      <td>Confident, Famously Funny, Fearless</td>\n",
       "      <td>148</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Regular Exercise</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Easy Training</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Outgoing</td>\n",
       "      <td>affenpinscher</td>\n",
       "      <td>affenpinscher</td>\n",
       "      <td>https://www.akc.org/wp-content/uploads/2017/11...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghan Hound</td>\n",
       "      <td>The Afghan Hound is an ancient breed, his whol...</td>\n",
       "      <td>Dignified, Profoundly Loyal, Aristocratic</td>\n",
       "      <td>113</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Energetic</td>\n",
       "      <td>0.2</td>\n",
       "      <td>May be Stubborn</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Aloof/Wary</td>\n",
       "      <td>afghan_hound</td>\n",
       "      <td>afghan_hound</td>\n",
       "      <td>https://s3.amazonaws.com/cdn-origin-etr.akc.or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airedale Terrier</td>\n",
       "      <td>The Airedale Terrier is the largest of all ter...</td>\n",
       "      <td>Friendly, Clever, Courageous</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Regular Exercise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eager to Please</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>airedale_terrier</td>\n",
       "      <td>airedale</td>\n",
       "      <td>https://s3.amazonaws.com/cdn-origin-etr.akc.or...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akita</td>\n",
       "      <td>Akitas are burly, heavy-boned spitz-type dogs ...</td>\n",
       "      <td>Courageous, Dignified, Profoundly Loyal</td>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Energetic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eager to Please</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Alert/Responsive</td>\n",
       "      <td>akita</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s3.amazonaws.com/cdn-origin-etr.akc.or...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaskan Malamute</td>\n",
       "      <td>The Alaskan Malamute stands 23 to 25 inches at...</td>\n",
       "      <td>Affectionate, Loyal, Playful</td>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Energetic</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>alaskan_malamute</td>\n",
       "      <td>malamute</td>\n",
       "      <td>https://s3.amazonaws.com/cdn-origin-etr.akc.or...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              breed                                        description  \\\n",
       "0     Affenpinscher  The Affen’s apish look has been described many...   \n",
       "1      Afghan Hound  The Afghan Hound is an ancient breed, his whol...   \n",
       "2  Airedale Terrier  The Airedale Terrier is the largest of all ter...   \n",
       "3             Akita  Akitas are burly, heavy-boned spitz-type dogs ...   \n",
       "4  Alaskan Malamute  The Alaskan Malamute stands 23 to 25 inches at...   \n",
       "\n",
       "                                 temperament  popularity  min_height  \\\n",
       "0        Confident, Famously Funny, Fearless         148          10   \n",
       "1  Dignified, Profoundly Loyal, Aristocratic         113          25   \n",
       "2               Friendly, Clever, Courageous          60          21   \n",
       "3    Courageous, Dignified, Profoundly Loyal          47          24   \n",
       "4               Affectionate, Loyal, Playful          58          23   \n",
       "\n",
       "   max_height  min_weight  max_weight  min_expectancy  max_expectancy  ...  \\\n",
       "0          12           7          12              12              15  ...   \n",
       "1          27          50          60              12              15  ...   \n",
       "2          23          44          50              11              14  ...   \n",
       "3          28          70         130              10              13  ...   \n",
       "4          25          75          85              10              14  ...   \n",
       "\n",
       "  energy_level_value  energy_level_category trainability_value  \\\n",
       "0                0.6       Regular Exercise                0.8   \n",
       "1                0.8              Energetic                0.2   \n",
       "2                0.6       Regular Exercise                1.0   \n",
       "3                0.8              Energetic                1.0   \n",
       "4                0.8              Energetic                0.4   \n",
       "\n",
       "   trainability_category demeanor_value  demeanor_category         akc_breed  \\\n",
       "0          Easy Training            1.0           Outgoing     affenpinscher   \n",
       "1        May be Stubborn            0.2         Aloof/Wary      afghan_hound   \n",
       "2        Eager to Please            0.8           Friendly  airedale_terrier   \n",
       "3        Eager to Please            0.6   Alert/Responsive             akita   \n",
       "4            Independent            0.8           Friendly  alaskan_malamute   \n",
       "\n",
       "    kaggle_breed                                           Img_Link  \\\n",
       "0  affenpinscher  https://www.akc.org/wp-content/uploads/2017/11...   \n",
       "1   afghan_hound  https://s3.amazonaws.com/cdn-origin-etr.akc.or...   \n",
       "2       airedale  https://s3.amazonaws.com/cdn-origin-etr.akc.or...   \n",
       "3            NaN  https://s3.amazonaws.com/cdn-origin-etr.akc.or...   \n",
       "4       malamute  https://s3.amazonaws.com/cdn-origin-etr.akc.or...   \n",
       "\n",
       "   group_values  \n",
       "0             0  \n",
       "1             1  \n",
       "2             2  \n",
       "3             3  \n",
       "4             3  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"../sourcedata/akc_dog_breed_cln.csv\")\n",
    "dog_breed_val_df = pd.read_csv(file_path)\n",
    "dog_breed_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['breed', 'description', 'temperament', 'popularity', 'min_height',\n",
       "       'max_height', 'min_weight', 'max_weight', 'min_expectancy',\n",
       "       'max_expectancy', 'group', 'grooming_frequency_value',\n",
       "       'grooming_frequency_category', 'shedding_value', 'shedding_category',\n",
       "       'energy_level_value', 'energy_level_category', 'trainability_value',\n",
       "       'trainability_category', 'demeanor_value', 'demeanor_category',\n",
       "       'akc_breed', 'kaggle_breed', 'Img_Link', 'group_values'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_breed_val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>min_height</th>\n",
       "      <th>max_height</th>\n",
       "      <th>min_weight</th>\n",
       "      <th>max_weight</th>\n",
       "      <th>min_expectancy</th>\n",
       "      <th>max_expectancy</th>\n",
       "      <th>grooming_frequency_value</th>\n",
       "      <th>shedding_value</th>\n",
       "      <th>energy_level_value</th>\n",
       "      <th>trainability_value</th>\n",
       "      <th>demeanor_value</th>\n",
       "      <th>group_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  min_height  max_height  min_weight  max_weight  min_expectancy  \\\n",
       "0         148          10          12           7          12              12   \n",
       "1         113          25          27          50          60              12   \n",
       "2          60          21          23          44          50              11   \n",
       "3          47          24          28          70         130              10   \n",
       "4          58          23          25          75          85              10   \n",
       "\n",
       "   max_expectancy  grooming_frequency_value  shedding_value  \\\n",
       "0              15                       0.6             0.6   \n",
       "1              15                       0.8             0.2   \n",
       "2              14                       0.6             0.4   \n",
       "3              13                       0.8             0.6   \n",
       "4              14                       0.6             0.6   \n",
       "\n",
       "   energy_level_value  trainability_value  demeanor_value  group_values  \n",
       "0                 0.6                 0.8             1.0             0  \n",
       "1                 0.8                 0.2             0.2             1  \n",
       "2                 0.6                 1.0             0.8             2  \n",
       "3                 0.8                 1.0             0.6             3  \n",
       "4                 0.8                 0.4             0.8             3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define features set\n",
    "col_to_drop = ['breed','group','description','grooming_frequency_category','shedding_category', \n",
    "                'energy_level_category', 'trainability_category', 'demeanor_category', 'temperament',\n",
    "                'akc_breed', 'kaggle_breed', 'Img_Link']\n",
    "X = dog_breed_val_df.copy()\n",
    "X.drop(col_to_drop, axis=1, inplace=True)\n",
    "X.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain negative values.\n"
     ]
    }
   ],
   "source": [
    "# Check for negative values in the entire DataFrame\n",
    "num_dog_breed_data_df = dog_breed_val_df.apply(pd.to_numeric, errors='ignore')\n",
    "has_negatives = (num_dog_breed_data_df._get_numeric_data() < 0).any().any()\n",
    "\n",
    "# If has_negatives is True, there are negative values; otherwise, there are no negative values\n",
    "if has_negatives:\n",
    "    print(\"The DataFrame contains negative values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not contain negative values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304700, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicating data\n",
    "dog_breed_new_df = [dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df,dog_breed_val_df]\n",
    "dog_breed_data_df = pd.concat(dog_breed_new_df)\n",
    "dog_breed_data_df = dog_breed_data_df.sample(frac = 100,replace=True).reset_index(drop=True)\n",
    "dog_breed_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>min_height</th>\n",
       "      <th>max_height</th>\n",
       "      <th>min_weight</th>\n",
       "      <th>max_weight</th>\n",
       "      <th>min_expectancy</th>\n",
       "      <th>max_expectancy</th>\n",
       "      <th>grooming_frequency_value</th>\n",
       "      <th>shedding_value</th>\n",
       "      <th>energy_level_value</th>\n",
       "      <th>trainability_value</th>\n",
       "      <th>demeanor_value</th>\n",
       "      <th>group_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  min_height  max_height  min_weight  max_weight  min_expectancy  \\\n",
       "0          85          17          19          40          70              12   \n",
       "1         174          12          14          32          40              10   \n",
       "2           0          17          20          26          40               9   \n",
       "3           0          23          28          62         110              12   \n",
       "4         118          26          30          80         130              10   \n",
       "\n",
       "   max_expectancy  grooming_frequency_value  shedding_value  \\\n",
       "0              16                       0.2             0.4   \n",
       "1              15                       0.6             0.4   \n",
       "2              13                       0.4             0.6   \n",
       "3              14                       0.6             0.8   \n",
       "4              12                       0.8             0.6   \n",
       "\n",
       "   energy_level_value  trainability_value  demeanor_value  group_values  \n",
       "0                 0.6                 0.6             0.6             2  \n",
       "1                 0.6                 0.4             0.6             2  \n",
       "2                 1.0                 0.8             0.4             4  \n",
       "3                 0.4                 0.8             0.6             4  \n",
       "4                 0.8                 0.8             0.4             3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features set\n",
    "# cat_col = ['grooming_frequency_category','shedding_category', 'energy_level_category', 'trainability_category', 'demeanor_category']\n",
    "# val_col = ['grooming_frequency_value', 'shedding_value', 'energy_level_value', 'trainability_value', 'demeanor_value']\n",
    "\n",
    "col_to_drop = ['breed','group','description','grooming_frequency_category','shedding_category',\n",
    "                'energy_level_category', 'trainability_category', 'demeanor_category', 'temperament',\n",
    "                'akc_breed', 'kaggle_breed', 'Img_Link']\n",
    "\n",
    "X = dog_breed_data_df.copy()\n",
    "X.drop(col_to_drop, axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate random float value between min_height and max_height\n",
    "# Apply the function to all rows and assign to 'min_height' column\n",
    "# Function to generate random float value between min_height and max_height\n",
    "# Apply the function to all rows and assign to 'min_height' column\n",
    "def generate_random_min_height(row):\n",
    "    return np.random.uniform(row['min_height'], row['min_height']+(row['max_height']-row['min_height']) / 2)\n",
    "\n",
    "def generate_random_max_height(row):\n",
    "    return np.random.uniform(row['min_height']+(row['max_height']-row['min_height']) / 2,row['max_height'])\n",
    "\n",
    "dog_breed_data_df['min_height'] = dog_breed_data_df.apply(generate_random_min_height, axis=1)\n",
    "dog_breed_data_df['max_height'] = dog_breed_data_df.apply(generate_random_max_height, axis=1)\n",
    "\n",
    "\n",
    "# Function to generate random float value between min_weight and max_weight\n",
    "# Apply the function to all rows and assign to 'weight' column\n",
    "def generate_random_min_weight(row):\n",
    "    return np.random.uniform(row['min_weight'], row['min_weight']+ (row['max_weight']-row['min_weight']) / 2)\n",
    "\n",
    "def generate_random_max_weight(row):\n",
    "    return np.random.uniform(row['min_weight']+(row['max_weight']-row['min_weight']) / 2,row['max_weight'])\n",
    "\n",
    "dog_breed_data_df['min_weight'] = dog_breed_data_df.apply(generate_random_min_weight, axis=1)\n",
    "dog_breed_data_df['max_weight'] = dog_breed_data_df.apply(generate_random_max_weight, axis=1)\n",
    "\n",
    "# Function to generate random float value between min_expectancy and max_expectancy\n",
    "# Apply the function to all rows and assign to 'expectancy' column\n",
    "def generate_random_min_expectancy(row):\n",
    "    return np.random.uniform(row['min_expectancy'], row['min_expectancy']+(row['max_expectancy']-row['min_expectancy']) / 2)\n",
    "\n",
    "def generate_random_max_expectancy(row):\n",
    "    return np.random.uniform(row['min_expectancy']+(row['max_expectancy']-row['min_expectancy']) / 2,row['max_expectancy'])\n",
    "\n",
    "dog_breed_data_df['min_expectancy'] = dog_breed_data_df.apply(generate_random_min_expectancy, axis=1)\n",
    "dog_breed_data_df['max_expectancy'] = dog_breed_data_df.apply(generate_random_max_expectancy, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain negative values.\n"
     ]
    }
   ],
   "source": [
    "# Check for negative values in the entire DataFrame\n",
    "num1_dog_breed_data_df = dog_breed_data_df.apply(pd.to_numeric, errors='ignore')\n",
    "has_negatives = (num1_dog_breed_data_df._get_numeric_data() < 0).any().any()\n",
    "\n",
    "# If has_negatives is True, there are negative values; otherwise, there are no negative values\n",
    "if has_negatives:\n",
    "    print(\"The DataFrame contains negative values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not contain negative values.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use label encoding to convert categorical values to numeric\n",
    "breed_labels, breed_mappings = pd.factorize(dog_breed_data_df['breed'])\n",
    "\n",
    "# Add the new numeric labels to the DataFrame\n",
    "dog_breed_data_df['breed_values'] = breed_labels\n",
    "\n",
    "# Print the DataFrame with the new numeric column\n",
    "dog_breed_data_df[['breed_values','breed']]\n",
    "# Define target vector\n",
    "y = dog_breed_data_df[\"breed_values\"].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304700 entries, 0 to 304699\n",
      "Data columns (total 26 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   breed                        304700 non-null  object \n",
      " 1   description                  304700 non-null  object \n",
      " 2   temperament                  304700 non-null  object \n",
      " 3   popularity                   304700 non-null  int64  \n",
      " 4   min_height                   304700 non-null  float64\n",
      " 5   max_height                   304700 non-null  float64\n",
      " 6   min_weight                   304700 non-null  float64\n",
      " 7   max_weight                   304700 non-null  float64\n",
      " 8   min_expectancy               304700 non-null  float64\n",
      " 9   max_expectancy               304700 non-null  float64\n",
      " 10  group                        304700 non-null  object \n",
      " 11  grooming_frequency_value     304700 non-null  float64\n",
      " 12  grooming_frequency_category  304700 non-null  object \n",
      " 13  shedding_value               304700 non-null  float64\n",
      " 14  shedding_category            304700 non-null  object \n",
      " 15  energy_level_value           304700 non-null  float64\n",
      " 16  energy_level_category        304700 non-null  object \n",
      " 17  trainability_value           304700 non-null  float64\n",
      " 18  trainability_category        304700 non-null  object \n",
      " 19  demeanor_value               304700 non-null  float64\n",
      " 20  demeanor_category            304700 non-null  object \n",
      " 21  akc_breed                    304700 non-null  object \n",
      " 22  kaggle_breed                 128303 non-null  object \n",
      " 23  Img_Link                     304700 non-null  object \n",
      " 24  group_values                 304700 non-null  int64  \n",
      " 25  breed_values                 304700 non-null  int64  \n",
      "dtypes: float64(11), int64(3), object(12)\n",
      "memory usage: 60.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dog_breed_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the decision tree classifier instance\n",
    "dt_model = tree.DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "dt_model = dt_model.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions Using the Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = dt_model.predict(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "#     cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "# )\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[310,   0,   0, ...,   0,   0,   0],\n",
       "       [  0, 281,   0, ...,   0,   0,   0],\n",
       "       [  0,   0, 274, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 275,   0,   0],\n",
       "       [  0,   0,   0, ...,   0, 265,   0],\n",
       "       [  0,   0,   0, ...,   0,   0, 293]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Confusion Matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  267  268  269  \\\n",
       "0    310    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1      0  281    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2      0    0  274    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3      0    0    0  293    0    0    0    0    0    0  ...    0    0    0   \n",
       "4      0    0    0    0  279    0    0    0    0    0  ...    0    0    0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "272    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "273    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "274    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "275    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "276    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "     270  271  272  273  274  275  276  \n",
       "0      0    0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "272    0    0  219    0    0    0    0  \n",
       "273    0    0    0  276    0    0    0  \n",
       "274    0    0    0    0  275    0    0  \n",
       "275    0    0    0    0    0  265    0  \n",
       "276    0    0    0    0    0    0  293  \n",
       "\n",
       "[277 rows x 277 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 1.0\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       310\n",
      "           1       1.00      1.00      1.00       281\n",
      "           2       1.00      1.00      1.00       274\n",
      "           3       1.00      1.00      1.00       293\n",
      "           4       1.00      1.00      1.00       279\n",
      "           5       1.00      1.00      1.00       279\n",
      "           6       1.00      1.00      1.00       282\n",
      "           7       1.00      1.00      1.00       270\n",
      "           8       1.00      1.00      1.00       257\n",
      "           9       1.00      1.00      1.00       296\n",
      "          10       1.00      1.00      1.00       263\n",
      "          11       1.00      1.00      1.00       281\n",
      "          12       1.00      1.00      1.00       257\n",
      "          13       1.00      1.00      1.00       267\n",
      "          14       1.00      1.00      1.00       289\n",
      "          15       1.00      1.00      1.00       284\n",
      "          16       1.00      1.00      1.00       294\n",
      "          17       1.00      1.00      1.00       291\n",
      "          18       1.00      1.00      1.00       293\n",
      "          19       1.00      1.00      1.00       276\n",
      "          20       1.00      1.00      1.00       291\n",
      "          21       1.00      1.00      1.00       299\n",
      "          22       1.00      1.00      1.00       245\n",
      "          23       1.00      1.00      1.00       274\n",
      "          24       1.00      1.00      1.00       251\n",
      "          25       1.00      1.00      1.00       256\n",
      "          26       1.00      1.00      1.00       281\n",
      "          27       1.00      1.00      1.00       279\n",
      "          28       1.00      1.00      1.00       251\n",
      "          29       1.00      1.00      1.00       290\n",
      "          30       1.00      1.00      1.00       276\n",
      "          31       1.00      1.00      1.00       295\n",
      "          32       1.00      1.00      1.00       264\n",
      "          33       1.00      1.00      1.00       269\n",
      "          34       1.00      1.00      1.00       284\n",
      "          35       1.00      1.00      1.00       281\n",
      "          36       1.00      1.00      1.00       319\n",
      "          37       1.00      1.00      1.00       293\n",
      "          38       1.00      1.00      1.00       233\n",
      "          39       1.00      1.00      1.00       266\n",
      "          40       1.00      1.00      1.00       293\n",
      "          41       1.00      1.00      1.00       271\n",
      "          42       1.00      1.00      1.00       285\n",
      "          43       1.00      1.00      1.00       281\n",
      "          44       1.00      1.00      1.00       295\n",
      "          45       1.00      1.00      1.00       276\n",
      "          46       1.00      1.00      1.00       283\n",
      "          47       1.00      1.00      1.00       287\n",
      "          48       1.00      1.00      1.00       289\n",
      "          49       1.00      1.00      1.00       245\n",
      "          50       1.00      1.00      1.00       278\n",
      "          51       1.00      1.00      1.00       263\n",
      "          52       1.00      1.00      1.00       280\n",
      "          53       1.00      1.00      1.00       247\n",
      "          54       1.00      1.00      1.00       282\n",
      "          55       1.00      1.00      1.00       249\n",
      "          56       1.00      1.00      1.00       266\n",
      "          57       1.00      1.00      1.00       282\n",
      "          58       1.00      1.00      1.00       293\n",
      "          59       1.00      1.00      1.00       270\n",
      "          60       1.00      1.00      1.00       294\n",
      "          61       1.00      1.00      1.00       272\n",
      "          62       1.00      1.00      1.00       300\n",
      "          63       1.00      1.00      1.00       243\n",
      "          64       1.00      1.00      1.00       272\n",
      "          65       1.00      1.00      1.00       271\n",
      "          66       1.00      1.00      1.00       286\n",
      "          67       1.00      1.00      1.00       272\n",
      "          68       1.00      1.00      1.00       246\n",
      "          69       1.00      1.00      1.00       275\n",
      "          70       1.00      1.00      1.00       262\n",
      "          71       1.00      1.00      1.00       265\n",
      "          72       1.00      1.00      1.00       263\n",
      "          73       1.00      1.00      1.00       289\n",
      "          74       1.00      1.00      1.00       301\n",
      "          75       1.00      1.00      1.00       249\n",
      "          76       1.00      1.00      1.00       307\n",
      "          77       1.00      1.00      1.00       271\n",
      "          78       1.00      1.00      1.00       315\n",
      "          79       1.00      1.00      1.00       261\n",
      "          80       1.00      1.00      1.00       273\n",
      "          81       1.00      1.00      1.00       310\n",
      "          82       1.00      1.00      1.00       273\n",
      "          83       1.00      1.00      1.00       259\n",
      "          84       1.00      1.00      1.00       287\n",
      "          85       1.00      1.00      1.00       266\n",
      "          86       1.00      1.00      1.00       255\n",
      "          87       1.00      1.00      1.00       296\n",
      "          88       1.00      1.00      1.00       268\n",
      "          89       1.00      1.00      1.00       270\n",
      "          90       1.00      1.00      1.00       248\n",
      "          91       1.00      1.00      1.00       323\n",
      "          92       1.00      1.00      1.00       276\n",
      "          93       1.00      1.00      1.00       271\n",
      "          94       1.00      1.00      1.00       304\n",
      "          95       1.00      1.00      1.00       269\n",
      "          96       1.00      1.00      1.00       279\n",
      "          97       1.00      1.00      1.00       271\n",
      "          98       1.00      1.00      1.00       304\n",
      "          99       1.00      1.00      1.00       284\n",
      "         100       1.00      1.00      1.00       263\n",
      "         101       1.00      1.00      1.00       281\n",
      "         102       1.00      1.00      1.00       283\n",
      "         103       1.00      1.00      1.00       275\n",
      "         104       1.00      1.00      1.00       264\n",
      "         105       1.00      1.00      1.00       253\n",
      "         106       1.00      1.00      1.00       275\n",
      "         107       1.00      1.00      1.00       293\n",
      "         108       1.00      1.00      1.00       260\n",
      "         109       1.00      1.00      1.00       280\n",
      "         110       1.00      1.00      1.00       273\n",
      "         111       1.00      1.00      1.00       297\n",
      "         112       1.00      1.00      1.00       295\n",
      "         113       1.00      1.00      1.00       269\n",
      "         114       1.00      1.00      1.00       241\n",
      "         115       1.00      1.00      1.00       292\n",
      "         116       1.00      1.00      1.00       283\n",
      "         117       1.00      1.00      1.00       277\n",
      "         118       1.00      1.00      1.00       249\n",
      "         119       1.00      1.00      1.00       266\n",
      "         120       1.00      1.00      1.00       310\n",
      "         121       1.00      1.00      1.00       284\n",
      "         122       1.00      1.00      1.00       247\n",
      "         123       1.00      1.00      1.00       297\n",
      "         124       1.00      1.00      1.00       279\n",
      "         125       1.00      1.00      1.00       277\n",
      "         126       1.00      1.00      1.00       279\n",
      "         127       1.00      1.00      1.00       279\n",
      "         128       1.00      1.00      1.00       274\n",
      "         129       1.00      1.00      1.00       263\n",
      "         130       1.00      1.00      1.00       308\n",
      "         131       1.00      1.00      1.00       222\n",
      "         132       1.00      1.00      1.00       265\n",
      "         133       1.00      1.00      1.00       310\n",
      "         134       1.00      1.00      1.00       263\n",
      "         135       1.00      1.00      1.00       260\n",
      "         136       1.00      1.00      1.00       261\n",
      "         137       1.00      1.00      1.00       274\n",
      "         138       1.00      1.00      1.00       260\n",
      "         139       1.00      1.00      1.00       246\n",
      "         140       1.00      1.00      1.00       290\n",
      "         141       1.00      1.00      1.00       275\n",
      "         142       1.00      1.00      1.00       271\n",
      "         143       1.00      1.00      1.00       283\n",
      "         144       1.00      1.00      1.00       275\n",
      "         145       1.00      1.00      1.00       263\n",
      "         146       1.00      1.00      1.00       249\n",
      "         147       1.00      1.00      1.00       281\n",
      "         148       1.00      1.00      1.00       281\n",
      "         149       1.00      1.00      1.00       284\n",
      "         150       1.00      1.00      1.00       294\n",
      "         151       1.00      1.00      1.00       280\n",
      "         152       1.00      1.00      1.00       262\n",
      "         153       1.00      1.00      1.00       285\n",
      "         154       1.00      1.00      1.00       283\n",
      "         155       1.00      1.00      1.00       286\n",
      "         156       1.00      1.00      1.00       253\n",
      "         157       1.00      1.00      1.00       241\n",
      "         158       1.00      1.00      1.00       290\n",
      "         159       1.00      1.00      1.00       295\n",
      "         160       1.00      1.00      1.00       270\n",
      "         161       1.00      1.00      1.00       282\n",
      "         162       1.00      1.00      1.00       257\n",
      "         163       1.00      1.00      1.00       296\n",
      "         164       1.00      1.00      1.00       268\n",
      "         165       1.00      1.00      1.00       245\n",
      "         166       1.00      1.00      1.00       287\n",
      "         167       1.00      1.00      1.00       241\n",
      "         168       1.00      1.00      1.00       253\n",
      "         169       1.00      1.00      1.00       292\n",
      "         170       1.00      1.00      1.00       270\n",
      "         171       1.00      1.00      1.00       286\n",
      "         172       1.00      1.00      1.00       271\n",
      "         173       1.00      1.00      1.00       296\n",
      "         174       1.00      1.00      1.00       288\n",
      "         175       1.00      1.00      1.00       293\n",
      "         176       1.00      1.00      1.00       297\n",
      "         177       1.00      1.00      1.00       274\n",
      "         178       1.00      1.00      1.00       290\n",
      "         179       1.00      1.00      1.00       251\n",
      "         180       1.00      1.00      1.00       270\n",
      "         181       1.00      1.00      1.00       279\n",
      "         182       1.00      1.00      1.00       245\n",
      "         183       1.00      1.00      1.00       300\n",
      "         184       1.00      1.00      1.00       261\n",
      "         185       1.00      1.00      1.00       264\n",
      "         186       1.00      1.00      1.00       260\n",
      "         187       1.00      1.00      1.00       287\n",
      "         188       1.00      1.00      1.00       275\n",
      "         189       1.00      1.00      1.00       279\n",
      "         190       1.00      1.00      1.00       297\n",
      "         191       1.00      1.00      1.00       277\n",
      "         192       1.00      1.00      1.00       241\n",
      "         193       1.00      1.00      1.00       265\n",
      "         194       1.00      1.00      1.00       264\n",
      "         195       1.00      1.00      1.00       271\n",
      "         196       1.00      1.00      1.00       283\n",
      "         197       1.00      1.00      1.00       296\n",
      "         198       1.00      1.00      1.00       302\n",
      "         199       1.00      1.00      1.00       254\n",
      "         200       1.00      1.00      1.00       273\n",
      "         201       1.00      1.00      1.00       287\n",
      "         202       1.00      1.00      1.00       266\n",
      "         203       1.00      1.00      1.00       254\n",
      "         204       1.00      1.00      1.00       294\n",
      "         205       1.00      1.00      1.00       239\n",
      "         206       1.00      1.00      1.00       284\n",
      "         207       1.00      1.00      1.00       266\n",
      "         208       1.00      1.00      1.00       248\n",
      "         209       1.00      1.00      1.00       264\n",
      "         210       1.00      1.00      1.00       290\n",
      "         211       1.00      1.00      1.00       289\n",
      "         212       1.00      1.00      1.00       267\n",
      "         213       1.00      1.00      1.00       264\n",
      "         214       1.00      1.00      1.00       285\n",
      "         215       1.00      1.00      1.00       264\n",
      "         216       1.00      1.00      1.00       282\n",
      "         217       1.00      1.00      1.00       251\n",
      "         218       1.00      1.00      1.00       263\n",
      "         219       1.00      1.00      1.00       252\n",
      "         220       1.00      1.00      1.00       265\n",
      "         221       1.00      1.00      1.00       272\n",
      "         222       1.00      1.00      1.00       262\n",
      "         223       1.00      1.00      1.00       270\n",
      "         224       1.00      1.00      1.00       263\n",
      "         225       1.00      1.00      1.00       269\n",
      "         226       1.00      1.00      1.00       280\n",
      "         227       1.00      1.00      1.00       279\n",
      "         228       1.00      1.00      1.00       292\n",
      "         229       1.00      1.00      1.00       275\n",
      "         230       1.00      1.00      1.00       252\n",
      "         231       1.00      1.00      1.00       255\n",
      "         232       1.00      1.00      1.00       288\n",
      "         233       1.00      1.00      1.00       268\n",
      "         234       1.00      1.00      1.00       272\n",
      "         235       1.00      1.00      1.00       265\n",
      "         236       1.00      1.00      1.00       265\n",
      "         237       1.00      1.00      1.00       301\n",
      "         238       1.00      1.00      1.00       270\n",
      "         239       1.00      1.00      1.00       282\n",
      "         240       1.00      1.00      1.00       284\n",
      "         241       1.00      1.00      1.00       289\n",
      "         242       1.00      1.00      1.00       284\n",
      "         243       1.00      1.00      1.00       289\n",
      "         244       1.00      1.00      1.00       278\n",
      "         245       1.00      1.00      1.00       298\n",
      "         246       1.00      1.00      1.00       273\n",
      "         247       1.00      1.00      1.00       274\n",
      "         248       1.00      1.00      1.00       278\n",
      "         249       1.00      1.00      1.00       298\n",
      "         250       1.00      1.00      1.00       260\n",
      "         251       1.00      1.00      1.00       293\n",
      "         252       1.00      1.00      1.00       294\n",
      "         253       1.00      1.00      1.00       290\n",
      "         254       1.00      1.00      1.00       275\n",
      "         255       1.00      1.00      1.00       269\n",
      "         256       1.00      1.00      1.00       240\n",
      "         257       1.00      1.00      1.00       293\n",
      "         258       1.00      1.00      1.00       233\n",
      "         259       1.00      1.00      1.00       294\n",
      "         260       1.00      1.00      1.00       258\n",
      "         261       1.00      1.00      1.00       273\n",
      "         262       1.00      1.00      1.00       283\n",
      "         263       1.00      1.00      1.00       270\n",
      "         264       1.00      1.00      1.00       281\n",
      "         265       1.00      1.00      1.00       279\n",
      "         266       1.00      1.00      1.00       265\n",
      "         267       1.00      1.00      1.00       245\n",
      "         268       1.00      1.00      1.00       295\n",
      "         269       1.00      1.00      1.00       283\n",
      "         270       1.00      1.00      1.00       274\n",
      "         271       1.00      1.00      1.00       275\n",
      "         272       1.00      1.00      1.00       219\n",
      "         273       1.00      1.00      1.00       276\n",
      "         274       1.00      1.00      1.00       275\n",
      "         275       1.00      1.00      1.00       265\n",
      "         276       1.00      1.00      1.00       293\n",
      "\n",
      "    accuracy                           1.00     76175\n",
      "   macro avg       1.00      1.00      1.00     76175\n",
      "weighted avg       1.00      1.00      1.00     76175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13719043637391304, 'popularity'),\n",
       " (0.09033839430079836, 'max_height'),\n",
       " (0.0873888625111319, 'max_weight'),\n",
       " (0.08353856149666089, 'min_height'),\n",
       " (0.08025146103382258, 'min_expectancy'),\n",
       " (0.07982997373648011, 'shedding_value'),\n",
       " (0.0720640092638916, 'min_weight'),\n",
       " (0.06865254321792484, 'group_values'),\n",
       " (0.0650057963760522, 'demeanor_value'),\n",
       " (0.06237716068909602, 'energy_level_value'),\n",
       " (0.05803599727191735, 'trainability_value'),\n",
       " (0.0577430857780964, 'grooming_frequency_value'),\n",
       " (0.057583717950214816, 'max_expectancy')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = dt_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(dt_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29a2d477248>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the features by importance\n",
    "importances_df = pd.DataFrame(sorted(zip(dt_model.feature_importances_, X.columns), reverse=True))\n",
    "importances_df.set_index(importances_df[1], inplace=True)\n",
    "importances_df.drop(columns=1, inplace=True)\n",
    "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)\n",
    "importances_sorted = importances_df.sort_values(by='Feature Importances')\n",
    "importances_sorted.plot(kind='barh', color='lightgreen', title= 'Features Importances', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126.    9.   10.   11.   12.   12.   16.    0.4   0.6   0.6   0.6   0.8\n",
      "    2. ]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the data from the Series and convert it to a numpy array\n",
    "user_val = 10\n",
    "user_input = []\n",
    "user_input = X.iloc[user_val].values\n",
    "# print(dog_breed_val_df[['breed','breed_values']].iloc[user_val])\n",
    "\n",
    "# # Reshape the user_input to a 2-dimensional array\n",
    "user_input_reshaped = user_input.reshape(1, -1)\n",
    "\n",
    "# # Now user_input_reshaped is a 2D array\n",
    "print((user_input_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94]\n",
      "[82]\n"
     ]
    }
   ],
   "source": [
    "new_predictions = dt_model.predict(user_input_reshaped)\n",
    "print(new_predictions)\n",
    "print(y[new_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Save Model Using Pickle\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'dog_app_dt_breed_pred.sav'\n",
    "pickle.dump(dt_model, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test_scaled, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
